Training Manual
---------------
<p align="left">
		<img src="https://img.shields.io/badge/version-0.2-brightgreen.svg?style=flat-square"
			 alt="Version">
		<img src="https://img.shields.io/badge/status-release-gold.svg?style=flat-square"
			 alt="Status">
		<img src="https://img.shields.io/badge/platform-win | linux-lightgrey.svg?style=flat-square"
			 alt="Platform">
		<img src="https://img.shields.io/badge/PyTorch version-1.0-blue.svg?style=flat-square"
			 alt="PyTorch">
		<img src="https://img.shields.io/badge/License-CC BYÂ·NC 4.0-green.svg?style=flat-square"
			 alt="License">
</p>

English | [ä¸­æ–‡ç‰ˆ](#jump_zh)

## Introduction
The whole training is not end-to-end which must be split into several phases to get a best performance.
So, reviewing the paper and codes structure will make you understand the training phase better.

As the paper shows, the whole model needs two separate models: `EdgeModel` and `InpaintingModel`.
But in practice, the whole work actually needs **three training phases** with **the two separate models**
, which makes results best while the training is confusing.

**IMPORTANT**: The three training phases I define here are called `model` in the original codes , which should not be confused with  `EdgeModel` and `InpaintingModel`.

Phase | Command | Model | Input | Output | Description
-----|-------|------|------|-------|-------
 1st | --model 1 | `EdgeModel` | Masked Greyscale Image + Masked Edge + Mask | Full Edge | Train `EdgeModel` solely
 2nd | --model 2 | `InpaintingModel` | Masked Image + Full canny Edge from Original full Image+  Mask | Full Image | Pre-train `InpaintingModel` solely to learn the importance of edges
 3rd | --model 3 | `InpaintingModel` | Masked Image + Full Edge from 1st phase output + Mask | Full Image | Actual train `InpaintingModel` with the predicted edges from phase 1

## Dataset
1. We need to prepare images dataset and masks dataset both.
- Mask dataset:
  - Irregular Mask Dataset ([download link](http://masc.cs.gmu.edu/wiki/uploads/partialconv/mask.zip)) provided by [Liu et al.](http://masc.cs.gmu.edu/wiki/partialconv) is recommended to handle with normal irregular defects.
  - Block Masks don't need dataset which can be random generated by codes.
- Image dataset:
  - Places2, CelebA and Paris Street-View datasets are [here](https://github.com/knazeri/edge-connect#datasets).
  - Anime Face dataset from `getchu.com` I used: [ANIME305](https://github.com/ANIME305/Anime-GAN-tensorflow#open-sourced-dataset)

2. We should split the whole image dataset into train/validation/test parts.
```bash
python scripts/flist_train_split.py --path <your dataset directory> --output <output path> --train 28 --val 1 --test 1
```
This script will split 30 images into 28 for train, 1 for validation and 1 for test.
Images are split by order of names instead of shuffle, in order to get a best time-average-distribution dataset.
Now there should be three `.filst` file in your `<output path>`, which conclude absolute image paths.

3. Copy the `config.yml.example` under root directory into your model path. Rename it into `config.yml` and edit it.
Here is some key parameters related to dataset:
- Edit the parameter `MASK: 3`(recommended as above, 4 is also feasible).
- Edit the parameter `TRAIN_FLIST`, `VAL_FLIST` and `TEST_FLIST` into your `.flist` path which are got in step 2.
- Edit the parameter `TRAIN_MASK_FLIST`, `VAL_MASK_FLIST` and `TEST_MASK_FLIST` into the same mask dataset path as we got in step 1.

Now my `config.yml` is:
```
MODE: 1             # 1: train, 2: test, 3: eval
MODEL: 1            # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model
MASK: 3             # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)
EDGE: 1             # 1: canny, 2: external
NMS: 1              # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny
SEED: 10            # random seed
DEVICE: 1           # 0: CPU, 1: GPU
GPU: [0]            # list of gpu ids
DEBUG: 1            # turns on debugging mode
VERBOSE: 0          # turns on verbose mode in the output console
SKIP_PHASE2: 1      # When training Inpaint model, 2nd and 3rd phases (model 2--->model 3 ) by order are needed. But we can merge 2nd phase into the 3rd one to speed up (however, lower performance).

TRAIN_FLIST: <your path>/train.flist
VAL_FLIST: <your path>/val.flist
TEST_FLIST: <your path>/test.flist

TRAIN_EDGE_FLIST: ./
VAL_EDGE_FLIST: ./
TEST_EDGE_FLIST: ./

# three options below could be the same
TRAIN_MASK_FLIST: <your mask dataset path>
VAL_MASK_FLIST: <your mask dataset path>
TEST_MASK_FLIST: <your mask dataset path>
```

## Training Prepare
- Download weights files: Which are available in [my page](README.md#run-the-tool) and [edge-connect](https://github.com/knazeri/edge-connect#2-testing)
- Strongly recommend you to start transfer learning with weight files. Otherwise you need about 10 days 2 million iterations training to coverage from scratch.
- mkdir a model path which contains the `config.yml` and four `.pth` weights files.
- edit the options in  `config.yml` related to training:
  - Edit the parameter `DEVICE: 1` which is a new option to use GPU or not.
  - Edit the parameter `GPU: [0]` to act a multi-gpu training.
  - Edit the parameter `INPUT_SIZE` to define the resize of input images
  - Edit the parameter `BATCH_SIZE` to adapt your GPU RAM
  - Edit the following options as u wish:
  ```
  SAVE_INTERVAL: 1000           # how many iterations to wait before saving model (0: never)
  SAMPLE_INTERVAL: 200         # how many iterations to wait before sampling (0: never)
  SAMPLE_SIZE: 12               # number of images to sample
  EVAL_INTERVAL: 0              # how many iterations to wait before model evaluation (0: never)
  LOG_INTERVAL: 1000              # how many iterations to wait before logging training status (0: never)
  PRINT_INTERVAL: 20            # how many iterations to wait before terminal prints training status (0: never)
  ```

## Training
Before training, there are two training optimizations in my work you must know:
- Add a skip phase 2 optional mode which can combine phase 2 and phase 3 together, in order to accelerate. If you cannot understand what it means, refer to the Introduction above.
- Feel free about the checkpoints problems, the new checkpoint files are saved in your same model path.
They are named followed by a iteration mark, e.g. `InpaintingModel_dis_2074000.pth`.
Also the latest checkpoints (identified by name) will be auto-load when the training begins.

### Faster Training steps
1. Train phase 1 which trains the `EdgeModel`.
```bash
python train.py --model 1 --path <your model dir path>
```
Check the samples at times and stop the training by yourself.

2. Train phase 2 and 3 together which trains the `InpaintingModel` using the well-trained `EdgeModel` in step 1.

 **IMPORTANT: `SKIP_PHASE2` should be `1` in `config.yml`!**
 ```bash
 python train.py --model 3 --path <your model dir path>
 ```
Check the samples at times and stop the training by yourself.
That's all!

### (optional) Advanced Training steps
- You can set `SKIP_PHASE2` into `0` in `config.yml` to train phase 2 (use `--model 2`), and phase 3 separately by *any* order.
- You can stop the training and then change the `SIGMA` in `config.yml`, then restart training. This way
is really tricky.


<span id="jump_zh">è®­ç»ƒæŒ‡å—ğŸ‡¨ğŸ‡³ </span>
------

## ç®€ä»‹ï¼ˆå¿…çœ‹ï¼‰
æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹å¹¶ä¸æ˜¯ç«¯åˆ°ç«¯ï¼ˆend-to-endï¼‰çš„ï¼Œæ ¹æ®è®ºæ–‡ä¸ºäº†å¾—åˆ°æœ€ä½³æ•ˆæœè®­ç»ƒè¢«åˆ†ä¸ºäº†å‡ ä¸ªé˜¶æ®µã€‚
æœ‰ç‚¹å¤æ‚ï¼Œæ‰€ä»¥ç†è§£è®ºæ–‡å¹¶æŸ¥çœ‹ä»£ç æ¡†æ¶å¯ä»¥è®©ä½ æ›´å¥½ç†è§£ã€‚

è®ºæ–‡ä¸­è¯´æ•´ä¸ªè®­ç»ƒé˜¶æ®µæœ‰ä¸¤ä¸ªå°æ¨¡å‹ï¼š`EdgeModel` å’Œ `InpaintingModel`.
ä½†æ˜¯æ ¹æ®ä»£ç ä¸ºäº†å¾—åˆ°æœ€ä½³æ•ˆæœï¼Œå®é™…ä¸Šæ•´ä¸ªè®­ç»ƒåˆ†ä¸ºè®­ç»ƒä¿©å°æ¨¡å‹å’Œä¸‰ä¸ªè®­ç»ƒé˜¶æ®µï¼Œè®­ç»ƒå®Œè¿˜è¦testå’Œevalï¼Œ
æ‰€ä»¥ä¸€åˆ‡å˜å¾—éƒ½ä»¤äººå›°æƒ‘ã€‚ä¸ç”¨æ‹…å¿ƒï¼Œè¿™ä¸ªæ‰‹å†Œå†™çš„å¯æ¸…æ™°äº†~

**é‡ç‚¹**ï¼šè¿™é‡Œè¢«æˆ‘æˆä¸ºé˜¶æ®µ`phase`ï¼Œåœ¨åŸä½œä»£ç ä¸­è¢«æˆä¸º`model`ï¼Œå› ä¸ºä¼šå’Œ`EdgeModel` å’Œ `InpaintingModel`æ··æ·†ï¼Œæ‰€ä»¥æˆ‘å«åšé˜¶æ®µã€‚
> e.g. è®­ç»ƒå‘½ä»¤è¡Œä¸­çš„ `--model` å‚æ•°æŒ‡å®šçš„å°±æ˜¯æˆ‘æ‰€è¯´çš„é˜¶æ®µ

é˜¶æ®µ | å¯¹åº”å‘½ä»¤è¡Œ | è®­ç»ƒçš„å°æ¨¡å‹ | è¾“å…¥ | è¾“å‡º | è¯´æ˜
-----|-------|------|------|-------|-------
 1st | --model 1 | `EdgeModel` | Masked Greyscale Image + Masked Edge + Mask | Full Edge | å•ç‹¬è®­ç»ƒ `EdgeModel`
 2nd | --model 2 | `InpaintingModel` | Masked Image + Full canny Edge from Original full Image+  Mask | Full Image | å•ç‹¬é¢„è®­ç»ƒ `InpaintingModel` ï¼Œä¸ºäº†è®©å®ƒå­¦åˆ°Edgeçš„é‡è¦æ€§
 3rd | --model 3 | `InpaintingModel` | Masked Image + Full Edge from 1st phase output + Mask | Full Image | çœŸæ­£çš„è®­ç»ƒ `InpaintingModel`ï¼Œä½¿ç”¨æ¥è‡ªé˜¶æ®µ1çš„è¾“å‡ºEdge

## æ•°æ®é›†å‡†å¤‡
1. æˆ‘ä»¬éœ€è¦åŒæ—¶å‡†å¤‡å›¾ç‰‡å’Œmaskæ•°æ®é›†ï¼š
- Mask dataset:
  - ä¸è§„åˆ™ Mask Dataset ([download link](http://masc.cs.gmu.edu/wiki/uploads/partialconv/mask.zip)) æ¥è‡ª [Liu et al.](http://masc.cs.gmu.edu/wiki/partialconv) ï¼Œæ¨èä½¿ç”¨è¿™ä¸ªæ¥å¯¹ä»˜ä¸è§„åˆ™çš„å›¾ç‰‡ç¼ºé™·ã€‚
  - è§„åˆ™çš„æ–¹å—maskä¸éœ€è¦æ•°æ®é›†ï¼Œå¯ä½¿ç”¨ä»£ç ç”Ÿæˆ
- Image dataset:
  - Places2, CelebA å’Œ Paris Street-View æ•°æ®é›†åœ¨ [è¿™é‡Œ](https://github.com/knazeri/edge-connect#datasets).
  - æ¥è‡ª`getchu.com`çš„åŠ¨æ¼«å¤´åƒæ•°æ®é›†åœ¨ [ANIME305](https://github.com/ANIME305/Anime-GAN-tensorflow#open-sourced-dataset)

2. æ¥ä¸‹æ¥æˆ‘ä»¬è¦æŠŠå›¾ç‰‡æ•°æ®åˆ†æˆtrain/validation/testä¸‰ä¸ªéƒ¨åˆ†ï¼ˆMaskæ•°æ®é›†ä¸ç”¨ï¼‰.
```bash
python scripts/flist_train_split.py --path <your dataset directory> --output <output path> --train 28 --val 1 --test 1
```
è¿™ä¸ªè„šæœ¬ä¼šé»˜è®¤å°†30å¼ å›¾ç‰‡åˆ†ä¸º28å¼ è®­ç»ƒï¼Œ1å¼ éªŒè¯ï¼Œ1å¼ æµ‹è¯•ã€‚æ³¨æ„ï¼Œåˆ†çš„æ—¶å€™æ²¡æœ‰shuffleæ‰“ä¹±ï¼Œæ˜¯æ ¹æ®æ–‡ä»¶åæ’åº
ä¸€è½®ä¸€è½®å‡åŒ€åˆ†çš„ï¼Œå› ä¸ºåŠ¨æ¼«å¤´åƒæ•°æ®é›†æ˜¯æŒ‰å¹´ä»£æ’åºçš„ï¼Œæˆ‘ä»¬æƒ³è®©æ•°æ®é›†åˆ†å¸ƒå‡åŒ€ã€‚è¯·ä¿®æ”¹è„šæœ¬ä»¥é€‚é…ä½ è‡ªå·±çš„æ•°æ®é›†ã€‚
ç°åœ¨ï¼Œåœ¨`<output path>`ç›®å½•ä¸‹åº”è¯¥æœ‰ä¸‰ä¸ª`.filst`æ–‡ä»¶äº†ï¼Œå®ƒä»¬åŒ…å«äº†å›¾ç‰‡çš„ç»å¯¹è·¯å¾„ã€‚

3. å¤åˆ¶æ ¹ç›®å½•ä¸‹çš„`config.yml.example`åˆ°ä½ çš„æ¨¡å‹æ–‡ä»¶å¤¹ä¸‹. é‡å‘½åä¸º`config.yml`å¹¶ç¼–è¾‘å®ƒ.
ä¸‹é¢æ˜¯å‡ ä¸ªå’Œæ•°æ®é›†æœ‰å…³çš„é…ç½®éœ€è¦ä¿®æ”¹ï¼š
- ä¿®æ”¹ `MASK: 3` (åŒæ ·æ¨èä½¿ç”¨4).
- ä¿®æ”¹ `TRAIN_FLIST`, `VAL_FLIST` å’Œ `TEST_FLIST` å˜æˆä½ çš„ `.flist` è·¯å¾„ã€‚
- ä¿®æ”¹ `TRAIN_MASK_FLIST`, `VAL_MASK_FLIST` å’Œ `TEST_MASK_FLIST` å˜æˆä½ çš„maskæ•°æ®é›†è·¯å¾„ï¼ˆä¸‰ä¸ªç›¸åŒï¼‰.

ç›®å‰ä¸ºæ­¢æˆ‘çš„ `config.yml` æ˜¯è¿™æ ·:
```
MODE: 1             # 1: train, 2: test, 3: eval
MODEL: 1            # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model
MASK: 3             # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)
EDGE: 1             # 1: canny, 2: external
NMS: 1              # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny
SEED: 10            # random seed
DEVICE: 1           # 0: CPU, 1: GPU
GPU: [0]            # list of gpu ids
DEBUG: 1            # turns on debugging mode
VERBOSE: 0          # turns on verbose mode in the output console
SKIP_PHASE2: 1      # When training Inpaint model, 2nd and 3rd phases (model 2--->model 3 ) by order are needed. But we can merge 2nd phase into the 3rd one to speed up (however, lower performance).

TRAIN_FLIST: <your path>/train.flist
VAL_FLIST: <your path>/val.flist
TEST_FLIST: <your path>/test.flist

TRAIN_EDGE_FLIST: ./
VAL_EDGE_FLIST: ./
TEST_EDGE_FLIST: ./

# three options below could be the same
TRAIN_MASK_FLIST: <your mask dataset path>
VAL_MASK_FLIST: <your mask dataset path>
TEST_MASK_FLIST: <your mask dataset path>
```

## è®­ç»ƒå‡†å¤‡
- åœ¨è¿™é‡Œ[my page](README.md#run-the-tool) å’Œè¿™é‡Œ [edge-connect](https://github.com/knazeri/edge-connect#2-testing) ä¸‹è½½é¢„è®­ç»ƒçš„æ¨¡å‹æ–‡ä»¶
- å¼ºçƒˆæ¨èä½ åœ¨é¢„è®­ç»ƒå¥½çš„æ–‡ä»¶ä¸Šè¿›è¡Œè¿ç§»å­¦ä¹ ã€‚ è¦çŸ¥é“ï¼Œä»0å¼€å§‹è®­ç»ƒå¤§æ¦‚è¦èŠ±è´¹10å¤©ï¼Œä¸¤ç™¾ä¸‡æ¬¡iterationsæ¥æ”¶æ•›åˆ°æœ€ä½³ï¼ˆè¿ç§»å­¦ä¹ å¤§æ¦‚ååˆ†ä¹‹ä¸€æ—¶é—´ï¼‰ã€‚
- æŠŠä½ çš„`config.yml`å’Œå››ä¸ªæƒé‡æ–‡ä»¶`.pth`æ”¾åˆ°åŒä¸€ä¸ªæ¨¡å‹ç›®å½•ä¸‹
- ä¿®æ”¹`config.yml` ä¸­æœ‰å…³è®­ç»ƒçš„é…ç½®:
  - ä¿®æ”¹ `DEVICE: 1` ä»£è¡¨æ˜¯å¦ä½¿ç”¨GPU.
  - ä¿®æ”¹ `GPU: [0]` å¦‚æœä½ æœ‰å¤šå—GPUè¿›è¡Œå¹¶è¡Œè®­ç»ƒçš„è¯.
  - ä¿®æ”¹ `INPUT_SIZE` æ¥å®šä¹‰è¾“å…¥å›¾ç‰‡çš„å‰ªè£å°ºå¯¸
  - ä¿®æ”¹ `BATCH_SIZE` ï¼Œä»¥é€‚åˆä½ çš„GPUæ˜¾å­˜
  - ä¿®æ”¹ä¸‹é¢çš„ä¸€äº›è®­ç»ƒæ—¶å‚æ•°ï¼š
  ```
  SAVE_INTERVAL: 1000           # how many iterations to wait before saving model (0: never)
  SAMPLE_INTERVAL: 200         # how many iterations to wait before sampling (0: never)
  SAMPLE_SIZE: 12               # number of images to sample
  EVAL_INTERVAL: 0              # how many iterations to wait before model evaluation (0: never)
  LOG_INTERVAL: 1000              # how many iterations to wait before logging training status (0: never)
  PRINT_INTERVAL: 20            # how many iterations to wait before terminal prints training status (0: never)
  ```

## è®­ç»ƒï¼å¯åŠ¨ï¼
è®­ç»ƒä¹‹å‰ï¼Œæ­¤é¡¹ç›®æœ‰ä¸¤ä¸ªä¼˜åŒ–ç‚¹ä½ å¿…é¡»äº†è§£ï¼š
- ä¸ºäº†åŠ é€Ÿè®­ç»ƒï¼Œæä¾›äº†ä¸€ç§è·³è¿‡é˜¶æ®µ2ï¼ˆå…¶å®æ˜¯åŒæ—¶ç»“åˆé˜¶æ®µ2å’Œé˜¶æ®µ3ï¼‰çš„è®­ç»ƒæ¨¡å¼ï¼Œå¯¹åº”é…ç½®`SKIP_PHASE2`ã€‚ä¸ç†è§£çš„è¯è¯·å›çœ‹ç®€ä»‹ä¸­çš„é˜¶æ®µè¯´æ˜ã€‚
- ä¸ç”¨æ‹…å¿ƒ`checkpoints`çš„å­˜å‚¨é—®é¢˜ï¼š
  - æ–°çš„`checkpoints`ä¼šè¢«å­˜å‚¨åœ¨æ¨¡å‹æ–‡ä»¶å¤¹ä¸‹ï¼Œåå­—æœ€åå¸¦æœ‰<iteration>å€¼ã€‚ä¾‹å¦‚ï¼š`InpaintingModel_dis_2074000.pth`.
  - åŒæ—¶ï¼Œå¼€å§‹è®­ç»ƒçš„æ—¶å€™ä¼šè‡ªåŠ¨åŠ è½½æœ€æ–°ï¼ˆæ ¹æ®æ–‡ä»¶ååˆ¤æ–­ï¼‰çš„`.pth`æ¨¡å‹æ–‡ä»¶ã€‚

### å¿«é€Ÿä¸¤è¡Œå‘½ä»¤è®­ç»ƒ
1. è®­ç»ƒé˜¶æ®µ1ï¼Œå¯¹åº”æ¨¡å‹ `EdgeModel`.
```bash
python train.py --model 1 --path <your model dir path>
```
æ—¶ä¸æ—¶æŸ¥çœ‹sampleï¼Œè‡ªå·±æ‰‹åŠ¨åœæ­¢ã€‚

2. è®­ç»ƒé˜¶æ®µ3ï¼Œå¯¹åº” `InpaintingModel` ï¼Œéœ€è¦ç”¨åˆ°ä¸Šä¸€æ­¥ä¸­è®­ç»ƒå¥½çš„`EdgeModel`çš„`.pth`ã€‚

 **é‡ç‚¹: æˆ‘ä»¬è·³è¿‡äº†è®­ç»ƒé˜¶æ®µ2ï¼ˆå®é™…ä¸Šæ˜¯èåˆäº†ï¼‰ï¼Œåœ¨ `config.yml`ä¸­`SKIP_PHASE2` å¿…é¡»é…ç½®ä¸º `1` !**
 ```bash
 python train.py --model 3 --path <your model dir path>
 ```
æ—¶ä¸æ—¶æŸ¥çœ‹sampleï¼Œè‡ªå·±æ‰‹åŠ¨åœæ­¢ã€‚ è®­ç»ƒå®Œæ¯•å•¦~


### (å¯é€‰) é«˜çº§è®­ç»ƒæ‰‹æ®µ
- é…ç½® `SKIP_PHASE2` ä¸º `0` æ¥è®­ç»ƒé˜¶æ®µ 2 (ä½¿ç”¨ `--model 2`),é˜¶æ®µ2å’Œ3èƒ½å¤Ÿä»¥ä»»ä½•é¡ºåºæ¥æ›¿è®­ç»ƒã€‚ä¾‹å¦‚ï¼š è®­ç»ƒ1å¤©é˜¶æ®µ2ï¼Œè®­ç»ƒ1å¤©é˜¶æ®µ3ï¼Œæ¥ç€è®­ç»ƒé˜¶æ®µ2â€¦â€¦ `checkpoints`æ–‡ä»¶ä¸éœ€è¦ä½ æ‹…å¿ƒã€‚
- ä¸­æ–­è®­ç»ƒåè°ƒæ•´ `SIGMA` é…ç½®, ç„¶åç»§ç»­è®­ç»ƒã€‚ï¼ˆtrickyï¼‰

